# AWS - S3, Athena & Glacier Enum

{% hint style="success" %}
Learn & practice AWS Hacking:<img src="/.gitbook/assets/image.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/image.png" alt="" data-size="line">\
Learn & practice GCP Hacking: <img src="/.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Support HackTricks</summary>

* Check the [**subscription plans**](https://github.com/sponsors/carlospolop)!
* **Join the** üí¨ [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** us on **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Share hacking tricks by submitting PRs to the** [**HackTricks**](https://github.com/carlospolop/hacktricks) and [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>
{% endhint %}

## S3

Amazon S3 es un servicio que te permite **almacenar grandes cantidades de datos**.

Amazon S3 proporciona m√∫ltiples opciones para lograr la **protecci√≥n** de datos en reposo. Las opciones incluyen **Permisos** (Pol√≠tica), **Cifrado** (Lado del Cliente y del Servidor), **Versionado de Bucket** y **eliminaci√≥n basada en MFA**. El **usuario puede habilitar** cualquiera de estas opciones para lograr la protecci√≥n de datos. **La replicaci√≥n de datos** es una funci√≥n interna de AWS donde **S3 replica autom√°ticamente cada objeto en todas las Zonas de Disponibilidad** y la organizaci√≥n no necesita habilitarlo en este caso.

Con permisos basados en recursos, puedes definir permisos para subdirectorios de tu bucket por separado.

### Versionado de Bucket y eliminaci√≥n basada en MFA

Cuando el versionado de bucket est√° habilitado, cualquier acci√≥n que intente alterar un archivo dentro de un archivo generar√° una nueva versi√≥n del archivo, manteniendo tambi√©n el contenido anterior del mismo. Por lo tanto, no sobrescribir√° su contenido.

Adem√°s, la eliminaci√≥n basada en MFA evitar√° que las versiones de archivo en el bucket S3 sean eliminadas y tambi√©n que el versionado de bucket sea deshabilitado, por lo que un atacante no podr√° alterar estos archivos.

Sin embargo, surge un riesgo potencial si los desarrolladores dejan informaci√≥n sensible como claves API, credenciales o antiguos puntos finales de API en las versiones anteriores de los archivos. Los atacantes o usuarios no autorizados que obtengan acceso a estas versiones m√°s antiguas podr√≠an explotar esta informaci√≥n si los permisos en el bucket o los objetos no est√°n debidamente asegurados.

Para verificar si un bucket habilita el versionado, puedes usar este comando:
```bash
aws s3api get-bucket-versioning --bucket <bucket_name>
```
Una posible salida se ve as√≠:
```json
{
"Status": "Enabled"
}
```
**Nota: Debes ser el propietario del bucket para recuperar el estado de versionado del bucket.**

Para ver todas las versiones de los objetos, intenta:

> Para usar esta operaci√≥n, debes tener permiso para realizar la acci√≥n s3:ListBucketVersions. Ten en cuenta la diferencia de nombres.
```bash
# try to remove --no-sign-request if you are authenticated
aws --no-sign-request s3api list-object-versions --bucket <bucket_name>
# redirect output into a file
aws --no-sign-request s3api list-object-versions --bucket <bucket_name> > versions.json
```
Para obtener una versi√≥n espec√≠fica de un objeto, intenta:
```bash
aws --no-sign-request s3api get-object --bucket <bucket_name> --key <object_key> --version-id <object_VersionId> <output_filename>
```
### S3 Access logs

Es posible **habilitar el registro de acceso de S3** (que por defecto est√° deshabilitado) para alg√∫n bucket y guardar los registros en un bucket diferente para saber qui√©n est√° accediendo al bucket (ambos buckets deben estar en la misma regi√≥n).

### S3 Presigned URLs

Es posible generar una URL firmada que generalmente se puede usar para **acceder al archivo especificado** en el bucket. Una **URL firmada se ve as√≠**:
```
https://<bucket-name>.s3.us-east-1.amazonaws.com/asd.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAUUE8GZC4S5L3TY3P%2F20230227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230227T142551Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBhQpdETJO3HKKDk2hjNIrPWwBE8gZaQccZFV3kCpPCWAiEAid3ueDtFFU%2FOQfUpvxYTGO%2BHoS4SWDMUrQAE0pIaB40qggMIYBAAGgwzMTgxNDIxMzg1NTMiDJLI5t7gr2EGxG1Y5CrfAioW0foHIQ074y4gvk0c%2B%2Fmqc7cNWb1njQslQkeePHkseJ3owzc%2FCwkgE0EuZTd4mw0aJciA2XIbJRCLPWTb%2FCBKPnIMJ5aBzIiA2ltsiUNQTTUxYmEgXZoJ6rFYgcodnmWW0Et4Xw59UlHnCDB2bLImxPprriyCzDDCD6nLyp3J8pFF1S8h3ZTJE7XguA8joMs4%2B2B1%2FeOZfuxXKyXPYSKQOOSbQiHUQc%2BFnOfwxleRL16prWk1t7TamvHR%2Bt3UgMn5QWzB3p8FgWwpJ6GjHLkYMJZ379tkimL1tJ7o%2BIod%2FMYrS7LDCifP9d%2FuYOhKWGhaakPuJKJh9fl%2B0vGl7kmApXigROxEWon6ms75laXebltsWwKcKuYca%2BUWu4jVJx%2BWUfI4ofoaGiCSaKALTqwu4QNBRT%2BMoK6h%2BQa7gN7JFGg322lkxRY53x27WMbUE4unn5EmI54T4dWt1%2Bg8ljDS%2BvKfBjqmAWRwuqyfwXa5YC3xxttOr3YVvR6%2BaXpzWtvNJQNnb6v0uI3%2BTtTexZkJpLQYqFcgZLQSxsXWSnf988qvASCIUhAzp2UnS1uqy7QjtD5T73zksYN2aesll7rvB80qIuujG6NOdHnRJ2M5%2FKXXNo1Yd15MtzPuSjRoSB9RSMon5jFu31OrQnA9eCUoawxbB0nHqwK8a43CKBZHhA8RoUAJW%2B48EuFsp3U%3D&X-Amz-Signature=3436e4139e84dbcf5e2e6086c0ebc92f4e1e9332b6fda24697bc339acbf2cdfa
```
Una URL prefirmada puede ser **creada desde la cli utilizando credenciales de un principal con acceso al objeto** (si la cuenta que usas no tiene acceso, se crear√° una URL prefirmada m√°s corta pero ser√° in√∫til)
```bash
aws s3 presign --region <bucket-region> 's3://<bucket-name>/<file-name>'
```
{% hint style="info" %}
El √∫nico permiso requerido para generar una URL firmada es el permiso que se est√° otorgando, por lo que para el comando anterior el √∫nico permiso necesario por el principal es `s3:GetObject`
{% endhint %}

Tambi√©n es posible crear URLs firmadas con **otros permisos**:
```python
import boto3
url = boto3.client('s3').generate_presigned_url(
ClientMethod='put_object',
Params={'Bucket': 'BUCKET_NAME', 'Key': 'OBJECT_KEY'},
ExpiresIn=3600
)
```
### Mecanismos de Cifrado de S3

**DEK significa Clave de Cifrado de Datos** y es la clave que siempre se genera y se utiliza para cifrar datos.

<details>

<summary><strong>Cifrado del lado del servidor con claves gestionadas por S3, SSE-S3</strong></summary>

Esta opci√≥n requiere una configuraci√≥n m√≠nima y toda la gesti√≥n de las claves de cifrado utilizadas es gestionada por AWS. Todo lo que necesitas hacer es **subir tus datos y S3 se encargar√° de todos los dem√°s aspectos**. A cada bucket en una cuenta de S3 se le asigna una clave de bucket.

* Cifrado:
* Datos del objeto + DEK en texto plano creado --> Datos cifrados (almacenados dentro de S3)
* DEK en texto plano creado + Clave Maestra de S3 --> DEK cifrado (almacenado dentro de S3) y el texto plano se elimina de la memoria
* Descifrado:
* DEK cifrado + Clave Maestra de S3 --> DEK en texto plano
* DEK en texto plano + Datos cifrados --> Datos del objeto

Por favor, ten en cuenta que en este caso **la clave es gestionada por AWS** (rotaci√≥n solo cada 3 a√±os). Si usas tu propia clave, podr√°s rotar, desactivar y aplicar control de acceso.

</details>

<details>

<summary><strong>Cifrado del lado del servidor con claves gestionadas por KMS, SSE-KMS</strong></summary>

Este m√©todo permite a S3 utilizar el servicio de gesti√≥n de claves para generar tus claves de cifrado de datos. KMS te ofrece una flexibilidad mucho mayor en c√≥mo se gestionan tus claves. Por ejemplo, puedes desactivar, rotar y aplicar controles de acceso a la CMK, y ordenar en contra de su uso utilizando AWS Cloud Trail.

* Cifrado:
* S3 solicita claves de datos a KMS CMK
* KMS utiliza una CMK para generar el par DEK en texto plano y DEK cifrado y los env√≠a a S3
* S3 utiliza la clave en texto plano para cifrar los datos, almacena los datos cifrados y la clave cifrada y elimina de la memoria la clave en texto plano
* Descifrado:
* S3 solicita a KMS que descifre la clave de datos cifrada del objeto
* KMS descifra la clave de datos con la CMK y la env√≠a de vuelta a S3
* S3 descifra los datos del objeto

</details>

<details>

<summary><strong>Cifrado del lado del servidor con claves proporcionadas por el cliente, SSE-C</strong></summary>

Esta opci√≥n te da la oportunidad de proporcionar tu propia clave maestra que ya puedes estar utilizando fuera de AWS. Tu clave proporcionada por el cliente se enviar√≠a con tus datos a S3, donde S3 realizar√≠a el cifrado por ti.

* Cifrado:
* El usuario env√≠a los datos del objeto + Clave del cliente a S3
* La clave del cliente se utiliza para cifrar los datos y los datos cifrados se almacenan
* tambi√©n se almacena un valor HMAC salado de la clave del cliente para futuras validaciones de clave
* la clave del cliente se elimina de la memoria
* Descifrado:
* El usuario env√≠a la clave del cliente
* La clave se valida contra el valor HMAC almacenado
* La clave proporcionada por el cliente se utiliza para descifrar los datos

</details>

<details>

<summary><strong>Cifrado del lado del cliente con KMS, CSE-KMS</strong></summary>

De manera similar a SSE-KMS, este tambi√©n utiliza el servicio de gesti√≥n de claves para generar tus claves de cifrado de datos. Sin embargo, esta vez KMS se invoca a trav√©s del cliente, no de S3. El cifrado se realiza del lado del cliente y los datos cifrados se env√≠an a S3 para ser almacenados.

* Cifrado:
* El cliente solicita una clave de datos a KMS
* KMS devuelve el DEK en texto plano y el DEK cifrado con la CMK
* Ambas claves se env√≠an de vuelta
* El cliente luego cifra los datos con el DEK en texto plano y env√≠a a S3 los datos cifrados + el DEK cifrado (que se guarda como metadatos de los datos cifrados dentro de S3)
* Descifrado:
* Los datos cifrados con el DEK cifrado se env√≠an al cliente
* El cliente solicita a KMS que descifre la clave cifrada utilizando la CMK y KMS env√≠a de vuelta el DEK en texto plano
* El cliente ahora puede descifrar los datos cifrados

</details>

<details>

<summary><strong>Cifrado del lado del cliente con claves proporcionadas por el cliente, CSE-C</strong></summary>

Usando este mecanismo, puedes utilizar tus propias claves proporcionadas y usar un cliente AWS-SDK para cifrar tus datos antes de enviarlos a S3 para su almacenamiento.

* Cifrado:
* El cliente genera un DEK y cifra los datos en texto plano
* Luego, utilizando su propia CMK personalizada, cifra el DEK
* env√≠a los datos cifrados + DEK cifrado a S3 donde se almacenan
* Descifrado:
* S3 env√≠a los datos cifrados y el DEK
* Como el cliente ya tiene la CMK utilizada para cifrar el DEK, descifra el DEK y luego utiliza el DEK en texto plano para descifrar los datos

</details>

### **Enumeraci√≥n**

Una de las principales formas tradicionales de comprometer organizaciones de AWS comienza por comprometer buckets accesibles p√∫blicamente. **Puedes encontrar** [**enumeradores de buckets p√∫blicos en esta p√°gina**](../../aws-security/aws-unauthenticated-enum-access/#s3-buckets)**.**
```bash
# Get buckets ACLs
aws s3api get-bucket-acl --bucket <bucket-name>
aws s3api get-object-acl --bucket <bucket-name> --key flag

# Get policy
aws s3api get-bucket-policy --bucket <bucket-name>
aws s3api get-bucket-policy-status --bucket <bucket-name> #if it's public

# list S3 buckets associated with a profile
aws s3 ls
aws s3api list-buckets

# list content of bucket (no creds)
aws s3 ls s3://bucket-name --no-sign-request
aws s3 ls s3://bucket-name --recursive

# list content of bucket (with creds)
aws s3 ls s3://bucket-name
aws s3api list-objects-v2 --bucket <bucket-name>
aws s3api list-objects --bucket <bucket-name>
aws s3api list-object-versions --bucket <bucket-name>

# list objects version history
# try to remove --no-sign-request if you are authenticated
aws --no-sign-request s3api list-object-versions --bucket <bucket_name>

# get a specific version for a object
aws --no-sign-request s3api get-object --bucket <bucket_name> --key <object_key> --version-id <object_VersionId> <output_filename>

# copy local folder to S3
aws s3 cp MyFolder s3://bucket-name --recursive

# delete
aws s3 rb s3://bucket-name ‚Äì-force

# download a whole S3 bucket
aws s3 sync s3://<bucket>/ .

# move S3 bucket to different location
aws s3 sync s3://oldbucket s3://newbucket --source-region us-west-1

# list the sizes of an S3 bucket and its contents
aws s3api list-objects --bucket BUCKETNAME --output json --query "[sum(Contents[].Size), length(Contents[])]"

# Update Bucket policy
aws s3api put-bucket-policy --policy file:///root/policy.json --bucket <bucket-name>
##JSON policy example
{
"Id": "Policy1568185116930",
"Version": "2012-10-17",
"Statement": [
{
"Sid": "Stmt1568184932403",
"Action": [
"s3:ListBucket"
],
"Effect": "Allow",
"Resource": "arn:aws:s3:::welcome",
"Principal": "*"
},
{
"Sid": "Stmt1568185007451",
"Action": [
"s3:GetObject"
],
"Effect": "Allow",
"Resource": "arn:aws:s3:::welcome/*",
"Principal": "*"
}
]
}

# Update bucket ACL
aws s3api get-bucket-acl --bucket <bucket-name> # Way 1 to get the ACL
aws s3api put-bucket-acl --bucket <bucket-name> --access-control-policy file://acl.json

aws s3api get-object-acl --bucket <bucket-name> --key flag #Way 2 to get the ACL
aws s3api put-object-acl --bucket <bucket-name> --key flag --access-control-policy file://objacl.json

##JSON ACL example
## Make sure to modify the Owner‚Äôs displayName and ID according to the Object ACL you retrieved.
{
"Owner": {
"DisplayName": "<DisplayName>",
"ID": "<ID>"
},
"Grants": [
{
"Grantee": {
"Type": "Group",
"URI": "http://acs.amazonaws.com/groups/global/AuthenticatedUsers"
},
"Permission": "FULL_CONTROL"
}
]
}
## An ACL should give you the permission WRITE_ACP to be able to put a new ACL
```
### dual-stack <a href="#dual-stack-endpoints-description" id="dual-stack-endpoints-description"></a>

Puedes acceder a un bucket de S3 a trav√©s de un endpoint de doble pila utilizando un nombre de endpoint de estilo hospedado virtual o de estilo de ruta. Estos son √∫tiles para acceder a S3 a trav√©s de IPv6.

Los endpoints de doble pila utilizan la siguiente sintaxis:

* `bucketname.s3.dualstack.aws-region.amazonaws.com`
* `s3.dualstack.aws-region.amazonaws.com/bucketname`

### Privesc

En la siguiente p√°gina puedes verificar c√≥mo **abusar de los permisos de S3 para escalar privilegios**:

{% content-ref url="../../aws-security/aws-privilege-escalation/aws-s3-privesc.md" %}
[aws-s3-privesc.md](../../aws-security/aws-privilege-escalation/aws-s3-privesc.md)
{% endcontent-ref %}

### Acceso no autenticado

{% content-ref url="../../aws-security/aws-unauthenticated-enum-access/aws-s3-unauthenticated-enum.md" %}
[aws-s3-unauthenticated-enum.md](../../aws-security/aws-unauthenticated-enum-access/aws-s3-unauthenticated-enum.md)
{% endcontent-ref %}

### S3 Post Explotaci√≥n

{% content-ref url="../aws-post-exploitation/aws-s3-post-exploitation.md" %}
[aws-s3-post-exploitation.md](../aws-post-exploitation/aws-s3-post-exploitation.md)
{% endcontent-ref %}

### Persistencia

{% content-ref url="../aws-persistence/aws-s3-persistence.md" %}
[aws-s3-persistence.md](../aws-persistence/aws-s3-persistence.md)
{% endcontent-ref %}

## Otras vulnerabilidades de S3

### Problema de envenenamiento de cach√© HTTP de S3 <a href="#heading-s3-http-desync-cache-poisoning-issue" id="heading-s3-http-desync-cache-poisoning-issue"></a>

[**Seg√∫n esta investigaci√≥n**](https://rafa.hashnode.dev/exploiting-http-parsers-inconsistencies#heading-s3-http-desync-cache-poisoning-issue) fue posible almacenar en cach√© la respuesta de un bucket arbitrario como si perteneciera a uno diferente. Esto podr√≠a haberse abusado para cambiar, por ejemplo, las respuestas de archivos javascript y comprometer p√°ginas arbitrarias utilizando S3 para almacenar c√≥digo est√°tico.

## Amazon Athena

Amazon Athena es un servicio de consulta interactivo que facilita **analizar datos** directamente en Amazon Simple Storage Service (Amazon **S3**) **usando** SQL **est√°ndar**.

Necesitas **preparar una tabla de base de datos relacional** con el formato del contenido que va a aparecer en los buckets de S3 monitoreados. Y luego, Amazon Athena podr√° poblar la base de datos a partir de los registros, para que puedas consultarla.

Amazon Athena admite la **capacidad de consultar datos de S3 que ya est√°n cifrados** y, si se configura para hacerlo, **Athena tambi√©n puede cifrar los resultados de la consulta que luego pueden ser almacenados en S3**.

**Este cifrado de resultados es independiente de los datos de S3 consultados subyacentes**, lo que significa que incluso si los datos de S3 no est√°n cifrados, los resultados consultados pueden estar cifrados. Un par de puntos a tener en cuenta es que Amazon Athena solo admite datos que han sido **cifrados** con los **siguientes m√©todos de cifrado de S3**, **SSE-S3, SSE-KMS y CSE-KMS**.

SSE-C y CSE-E no son compatibles. Adem√°s de esto, es importante entender que Amazon Athena solo ejecutar√° consultas contra **objetos cifrados que est√©n en la misma regi√≥n que la consulta misma**. Si necesitas consultar datos de S3 que han sido cifrados usando KMS, entonces se requieren permisos espec√≠ficos por parte del usuario de Athena para permitirles realizar la consulta.

### Enumeraci√≥n
```bash
# Get catalogs
aws athena list-data-catalogs

# Get databases inside catalog
aws athena list-databases --catalog-name <catalog-name>
aws athena list-table-metadata --catalog-name <catalog-name> --database-name <db-name>

# Get query executions, queries and results
aws athena list-query-executions
aws athena get-query-execution --query-execution-id <id> # Get query and meta of results
aws athena get-query-results --query-execution-id <id> # This will rerun the query and get the results

# Get workgroups & Prepared statements
aws athena list-work-groups
aws athena list-prepared-statements --work-group <wg-name>
aws athena get-prepared-statement --statement-name <name> --work-group <wg-name>

# Run query
aws athena start-query-execution --query-string <query>
```
## Referencias

* [https://cloudsecdocs.com/aws/defensive/tooling/cli/#s3](https://cloudsecdocs.com/aws/defensive/tooling/cli/#s3)
* [https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html)

{% hint style="success" %}
Aprende y practica Hacking en AWS:<img src="/.gitbook/assets/image.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/image.png" alt="" data-size="line">\
Aprende y practica Hacking en GCP: <img src="/.gitbook/assets/image (2).png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/image (2).png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Apoya a HackTricks</summary>

* Revisa los [**planes de suscripci√≥n**](https://github.com/sponsors/carlospolop)!
* **√önete al** üí¨ [**grupo de Discord**](https://discord.gg/hRep4RUj7f) o al [**grupo de telegram**](https://t.me/peass) o **s√≠guenos** en **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Comparte trucos de hacking enviando PRs a los** [**HackTricks**](https://github.com/carlospolop/hacktricks) y [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) repositorios de github.

</details>
{% endhint %}
